# Deep Learning Projects

<br/>

|S.No|   Projects                                              |
|-----|----------------------------------------------------------|
| 01. |[Cats vs Dogs Classifier](#p-cats-vs-dogs-classifier)|
| 02. |[Rock Paper and Scissors Classifier](#p-rock-paper-and-scissors-classifier)|
| 03. |[American Sign Language Classifier](#p-american-sign-language-classifier)|


<br/>


<!-- 1 -->
## P. ***Cats vs Dogs Classifier***
#### Concepts used:
<b> Transfer Learning (Binary Classification) </b>
1. Transfer Learning (pre-trained InceptionV3 network)
2. Data Augmentation
3. Regularization using Dropouts ( to make network more efficient and prevent overfitting)


<div align="right">
    <b><a href="#">↥ back to top</a></b>
</div>

<!-- 2 -->
## P. ***Rock Paper and Scissors Classifier***
#### Concepts used:
<b> Multiclass Classification</b>
1. Data Augmentation
2. Regularization using Dropouts ( to make network more efficient and prevent overfitting)

<div align="right">
    <b><a href="#">↥ back to top</a></b>
</div>


## P. American Sign Language Classifier 
#### Concepts used:
<b>Multiclass Classificaton)</b>
1. Data Augmentation
2. Convolution Neural Networks

<div align='right'>
    <b><a href="#">↥ back to top</b>
</div>

### 4) Humans vs Horses Classifier using Transfer Learning
#### Concepts used:
1. Transfer Learning (pre-trained InceptionV3 network)
2. Data Augmentation
3. Regularization using Dropouts ( to make network more efficient and prevent overfitting)
4. Callbacks (stops training when reached at certain level)

### 5) GAN
#### Concepts used:
1. Generator
2. Discriminator (Classifier)
3. Linear Transformation
4. Batch Normalization


### 6) Deep Convolution GAN (DC-GAN)
#### Concepts used:
1. Generator
2. Discriminator (Classifier)
3. Batch Normalization
4. Transpose Convolution

### 7) Conditional GAN (C-GAN)
#### Concepts used:
1. Generator
2. Descrimantor
3. BatchNorm
4. Transpose Convolution

### 8) Wasserstein GAN (W-GAN)
#### Concepts used:
1. Generator
2. Critic (Discriminator/Classifier)
3. BatchNorm
4. Transpose Convolution
5. Gradient Penalty (To prevent mode collapse)
6. Wasserstein loss

### 9) Text Classification (NLP)
#### Concepts used:
1. Word Embedding
2. Tokens
3. Pad Sequence
4. Visualization using Tensorflow Projector

